---
layout: default     # use your main layout
title: Home         # page title
---

# My understanding of supervised learning for fraud detection 

## The goal of this series of posts

I’m writing this series to lock in my own understanding of supervised learning techniques in fraud detection. I’m not writing this as a tutorial for others, but if you find this helpful to advance your own understanding, great. I’ll use the mathematical and statistical language that makes sense to me and skip explanations of those foundations.  I’ll assume familiarity with basic elements of machine learning, like model fitting, validation, and tuning hyperparameters and familiarity with Python, Jupyter, and scikit-learn.
Having read a lot of material explaining machine learning in non-specific terms, I am most interested in:
•	a clear understanding of the models, metrics, and assorted techniques commonly used in fraud detection, and
•	what sets supervised learning for fraud detection apart from supervised learning in general (such as the extreme class imbalance, and the different costs for false positives vs false negatives)
When possible, I’d also like to have a visual understanding (yeah, right).  
Caution: These posts reflect my own understanding of the techniques I write about. No one has reviewed or verified the accuracy of my statements besides me. As you can tell from the “lock in my understanding” phrase, I am a newbie to fraud detection. Despite a lack of credentials, I will occasionally put forth my own reactions to choices made in the Handbook, along with my reasoning, for what they are worth. That all said, I cite sources where relevant and always welcome constructive comments or corrections.